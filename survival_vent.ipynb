{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('imputed_m.csv')\n",
    "df = df.drop(axis=1, columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Post-pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abc5d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['hadm_id', 'subject_id']\n"
     ]
    }
   ],
   "source": [
    "# variables for analysis\n",
    "categorical = ['ethnicity', \n",
    "              'marital_status',\n",
    "              'language',\n",
    "              'admission_location',\n",
    "              'gender',\n",
    "              'insurance',\n",
    "              'first_careunit',\n",
    "              'last_careunit',\n",
    "              'admission_type']\n",
    "proceduretype=['aortic','mit','tricuspid','pulmonary','cabg']\n",
    "ptParams = ['weight', 'height']\n",
    "boolFields = ['reintubation', 'liver_severe', 'liver_mild', 'rheum', 'cvd', 'aids', 'ckd', 'copd', 'arrhythmia', 'pud', 'smoking', 'pvd', 'paraplegia', \n",
    "              'ccf', 'met_ca', 't2dm', 't1dm', 'malig', 'mi', 'dementia', 'hospital_expire_flag', 'diab_un', 'diab_cc','infection_vent']\n",
    "ptinfo = ['hadm_id', 'subject_id']\n",
    "ptTimes = ['int_time1','ext_time1','int_time2','ext_time2','admittime', 'dischtime', 'deathtime','intime', 'outtime', 'ext_time', 'icustay_seq']\n",
    "tsColumns = [i for i in df.columns if '_max' in i or '_min' in i or '_mean' in i]\n",
    "\n",
    "inputs = [*categorical , *proceduretype , *tsColumns , *ptParams , *boolFields]\n",
    "outcomes = ['reintubation','hospital_expire_flag','los','duration1','duration2','icu_stay_duration']\n",
    "\n",
    "print([i for i in df.columns if i not in categorical + proceduretype + tsColumns + ptParams + boolFields + ptinfo + ptTimes + outcomes])\n",
    "print([i for i in df.columns if i not in inputs + outcomes + ptTimes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical to category type\n",
    "for col in categorical:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number censored: 4\n",
      "[2500, 2962, 3106, 8193]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9474"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create censor column for death before extubation\n",
    "censor = []\n",
    "for i in range(len(df)):\n",
    "    if df['deathtime'][i] is np.NaN or df['deathtime'][i] >= df['ext_time1'][i]:\n",
    "        censor.append(True)\n",
    "    else:\n",
    "        censor.append(False)\n",
    "censored = []\n",
    "for i in range(len(censor)):\n",
    "    if censor[i] == False:\n",
    "        censored.append(i)\n",
    "print('Number censored: '+str(len(censored)))\n",
    "print(censored)\n",
    "\n",
    "df['censor'] = censor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a701fa",
   "metadata": {},
   "source": [
    "## 2: DL Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e98102",
   "metadata": {},
   "source": [
    "### 2.1: Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1d57eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( True,  3. ), ( True,  3. ), ( True, 17.5), ..., ( True,  8. ),\n",
       "       ( True, 12. ), ( True, 45. )],\n",
       "      dtype=[('Censor', '?'), ('Survival', '<f8')])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[inputs]\n",
    "Xt = OneHotEncoder().fit_transform(X)\n",
    "\n",
    "y = np.zeros(len(df), dtype={'names':('Censor', 'Survival'),\n",
    "                          'formats':('?', '<f8')})\n",
    "\n",
    "y['Censor'] = df['censor']\n",
    "y['Survival'] =df['duration1']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12128/3690819877.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcoefficients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tridentenv\\lib\\site-packages\\sksurv\\linear_model\\coxph.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             delta = solve(optimizer.hessian, optimizer.gradient,\n\u001b[0;32m    427\u001b[0m                           overwrite_a=False, overwrite_b=False, check_finite=False)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tridentenv\\lib\\site-packages\\sksurv\\linear_model\\coxph.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, w, offset)\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \u001b[0mhessian\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_events\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minv_n_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[0mnumerator\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mn_events\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alphas = 10. ** np.linspace(-4, 4, 50)\n",
    "coefficients = {}\n",
    "\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "for alpha in alphas:\n",
    "    cph.set_params(alpha=alpha)\n",
    "    cph.fit(Xt, y)\n",
    "    key = round(alpha, 5)\n",
    "    coefficients[key] = cph.coef_\n",
    "\n",
    "coefficients = (pd.DataFrame\n",
    "    .from_dict(coefficients)\n",
    "    .rename_axis(index=\"feature\", columns=\"alpha\")\n",
    "    .set_index(Xt.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd547661",
   "metadata": {},
   "source": [
    "## 3: Exploring language and ventilation duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c083716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "dfImputed_onehot = dfImputed.copy()\n",
    "dfImputed1 = pd.get_dummies(dfImputed_onehot, columns = ['ethnicity', 'language'], prefix = ['eth', 'lang'])\n",
    "onehot_cols = [i for i in list(dfImputed1.columns) if i not in ['ethnicity', 'marital_status', 'language', 'admission_location']]\n",
    "dfImputed1['duration1'] = df['duration1']\n",
    "dfImputed1 = dfImputed1.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfImputed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from scipy.stats import kstest, norm, pearsonr, ttest_ind\n",
    "\n",
    "x = dfImputed1['lang_ENGL']\n",
    "y = df['duration1'].dropna(axis=0,how='any')\n",
    "\n",
    "#testing for normalcy\n",
    "mu, std = norm.fit(x)\n",
    "n = norm(loc=mu, scale=std)\n",
    "normalcy_p = kstest(x, n.cdf)[1]\n",
    "print('p-val: '+ str(normalcy_p))\n",
    "\n",
    "pyplot.scatter(x,y)\n",
    "covariance = np.cov(x,y)\n",
    "print('Covariance matrix: ')\n",
    "print(covariance)\n",
    "\n",
    "#find pearson R\n",
    "corr, _ = pearsonr(x,y)\n",
    "print('Pearsons R: %.3f' %corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9eb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "univariable = pd.DataFrame(index = ['eth_white','lang_ENGL'], columns = ['OR (95% CI)','p-value'])\n",
    "\n",
    "p_value = []\n",
    "OR = []\n",
    "time = []\n",
    "for column in ['lang_ENGL']:\n",
    "    for int_timelimit in range(0,48,1):\n",
    "        X = dfImputed1[column].values\n",
    "        X = sm.add_constant(X)\n",
    "        y = pd.cut(df['duration1'].dropna(how='any'),bins=[-0.1,int_timelimit,4000],labels=[0,1])\n",
    "        logit = sm.Logit(y, X)\n",
    "        model = logit.fit(method='bfgs',disp = False)\n",
    "        model_odds = pd.DataFrame(np.exp(model.params), columns=['OR'])\n",
    "        model_odds['p-value'] = model.pvalues\n",
    "        model_odds[['2.5%','97.5%']]= np.exp(model.conf_int())\n",
    "        model_odds.rename(index={'x1': column}, inplace = True)\n",
    "        # insert it into the dataframe 'univariable'\n",
    "        univariable.at[column,'OR (95% CI)'] = '{OR:.3f} ({lower:.3f} to {upper:.3f})'.format(OR = model_odds.at[column, 'OR'], \n",
    "                                                                                            lower = model_odds.at[column, '2.5%'], \n",
    "                                                                                            upper = model_odds.at[column, '97.5%'])\n",
    "        univariable.at[column,'p-value'] = '{0:.3f}'.format(model_odds.at[column, 'p-value'])\n",
    "        p_value.append(model_odds.at[column, 'p-value'])\n",
    "        OR.append(model_odds.at[column, 'OR'])\n",
    "        time.append(int_timelimit)\n",
    "\n",
    "univariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, OR, label='OR',color='blue')\n",
    "ax.set_xlabel(\"ventilation time\")\n",
    "ax.set_ylabel(\"OR\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(time, p_value, label='p-val',color='orange')\n",
    "ax2.set_ylabel(\"p-val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dfImputed1['duration1'][dfImputed1['lang_ENGL']==1].dropna(axis=0,how='any')\n",
    "x2 = dfImputed1['duration1'][dfImputed1['lang_ENGL']==0].dropna(axis=0,how='any')\n",
    "plt.hist(x1,bins=[-0.1,2,4,6,10,13,16,20,25,30,40,50,60],range=(0,60))\n",
    "plt.hist(x2,bins=[-0.1,2,4,6,10,13,16,20,25,30,40,50,60],range=(0,60),color='orange')\n",
    "print('mean English: '+str(np.mean(x1)))\n",
    "print('mean non-English: '+str(np.mean(x2)))\n",
    "print('t_test p-val;: '+str(ttest_ind(x1, x2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd6b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0652ecffa332becfb8e0a3b24d51fbf4b8e2da78993fa6a399295ab431c37288"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tridentenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
