{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f56f0f",
   "metadata": {},
   "source": [
    "# DL Survival - Ventilation Outcomes\n",
    " Updated 21/11/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eaaedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import miceforest as mf\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8194f0a",
   "metadata": {},
   "source": [
    "## 1. Data cleaning\n",
    "\n",
    "- Import MIMIC III data\n",
    "- Review column unique values, assign correct data types\n",
    "- Impute missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346094f4",
   "metadata": {},
   "source": [
    "### 1.1: Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb38842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mimic_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f101fe",
   "metadata": {},
   "source": [
    "#### 1.1.1: Column lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95780e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view and reorder columns\n",
    "cols = list(df.columns)\n",
    "new_cols = ['Unnamed: 0','hadm_id','subject_id','gender','ethnicity','marital_status','insurance','language','aortic','mit','tricuspid',\n",
    "            'pulmonary','cabg','temp','bg_temp','hr','spo2','rr','sbp','dbp','meanbp','weight','height','cardiac_index','pt','ptt',\n",
    "            'inr','inr_1','fibrinogen','hb','hematocrit','plts','wcc','lymphocytes','neutrophils','alp','ast','alt','ggt',\n",
    "            'bilirubin_indirect','bilirubin_direct','bilirubin_total','chloride','magnesium','potassium','crp','bleed_time','albumin',\n",
    "            'creatinine','free_calcium','sodium','bicarb','bun','hba1c','glucose','lactate','po2','pco2','baseexcess','ph','aado2',\n",
    "            'fio2','ffp','insulin','cryo','prbc','infection','ventrate','tidalvol','vent_array','reintubation','liver_severe','liver_mild',\n",
    "            'rheum','cvd','aids','ckd','copd','arrhythmia','pud','smoking','pvd','paraplegia','ccf','met_ca','t2dm','t1dm','malig','mi',\n",
    "            'dementia','first_careunit','last_careunit','admission_location','admission_type','hospital_expire_flag','admittime',\n",
    "            'dischtime','intime','outtime','ext_time','reint_time','los','icustay_seq','deathtime','plt','diab_un','diab_cc',\n",
    "            'dtoutput','specimen','dod']\n",
    "\n",
    "ptinfo=['Unnamed: 0','hadm_id','subject_id']\n",
    "\n",
    "demographics=['gender','ethnicity','marital_status','insurance','language']\n",
    "\n",
    "proceduretype=['aortic','mit','tricuspid','pulmonary','cabg']\n",
    "\n",
    "vitals=['temp','bg_temp','hr','spo2','rr','sbp','dbp','meanbp','weight','height','cardiac_index']\n",
    "\n",
    "labs=['pt','ptt','inr','inr_1','fibrinogen','hb','hematocrit','plts','wcc','lymphocytes','neutrophils','alp','ast','alt','ggt',\n",
    "'bilirubin_indirect','bilirubin_direct','bilirubin_total','chloride','magnesium','potassium','crp','bleed_time',\n",
    "'albumin','creatinine','free_calcium','sodium','bicarb','bun','hba1c','glucose','lactate']\n",
    "\n",
    "bloodgases=['po2','pco2','baseexcess','ph','aado2','fio2']\n",
    "\n",
    "products=['ffp','insulin','cryo','prbc','infection']\n",
    "\n",
    "ventilation=['ventrate','tidalvol','vent_array','reintubation']\n",
    "\n",
    "comorbidities=['liver_severe','liver_mild','rheum','cvd','aids','ckd','copd','arrhythmia','pud','smoking','pvd',\n",
    "'paraplegia','ccf','met_ca','t2dm','t1dm','malig','mi','dementia']\n",
    "\n",
    "adm_cat=['first_careunit','last_careunit','admission_location','admission_type','hospital_expire_flag']\n",
    "\n",
    "adm_num=['admittime','dischtime','intime','outtime','ext_time','reint_time','los','icustay_seq','deathtime']\n",
    "\n",
    "others=['plt','diab_un','diab_cc','dtoutput','specimen','dod']\n",
    "\n",
    "timeseries=[*vitals,*labs,*bloodgases,*products,*ventilation,'plt','dtoutput']\n",
    "timeseries = [i for i in timeseries if i not in ('weight','height','reintubation', 'infection', 'vent_array')]\n",
    "    \n",
    "timeseries_valuenames = {'cardiac_index':'ci',\n",
    "                         'plts':'bloodproduct',\n",
    "                         'ffp':'bloodproduct',\n",
    "                         'insulin':'amount',\n",
    "                         'cryo':'bloodproduct',\n",
    "                         'prbc':'bloodproduct',\n",
    "                         'dtoutput':'output'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[new_cols]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f2201",
   "metadata": {},
   "source": [
    "### 1.2: Cleaning data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def94863",
   "metadata": {},
   "source": [
    "#### 1.2.0: NaN assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dae754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('NaT',np.datetime64('NaT'))\n",
    "df = df.replace(['[]','NaN',np.datetime64('NaT')],np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c1b51",
   "metadata": {},
   "source": [
    "#### 1.2.1: Datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c51d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column types as datetime\n",
    "time_cols = ['admittime','dischtime','intime','outtime','reint_time','ext_time','deathtime']\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#dod\n",
    "df['dod'] = pd.to_datetime(df['dod'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23456e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK FOR ROWS WHERE DEATHTIME < INTIME OR ADMITTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[time_cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b3b66",
   "metadata": {},
   "source": [
    "#### 1.2.2: Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41125aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in demographics:\n",
    "    print(x,': ',df[x].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ethnicity\n",
    "df.replace({'ethnicity':\n",
    "                {'unknown': np.NaN,'UNKNOWN':np.NaN,'UNABLE TO OBTAIN':np.NaN,\n",
    "                'OTHER':'other','WHITE':'white','BLACK/AFRICAN AMERICAN':'black','ASIAN':'asian',\n",
    "                'HISPANIC/LATINO':'hispanic','AMERICAN INDIAN/ALASKA NATIVE':'native'\n",
    "                }\n",
    "            }, \n",
    "            inplace=True)\n",
    "print(df['ethnicity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab789eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#marital_status\n",
    "df.replace({'marital_status':\n",
    "                {'UNKNOWN (DEFAULT)': np.NaN\n",
    "                }\n",
    "            }, \n",
    "            inplace=True)\n",
    "print(df['marital_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#language\n",
    "df.replace({'language':\n",
    "                {'ENGLISH':'ENGL','?':np.NaN\n",
    "                }\n",
    "            }, \n",
    "            inplace=True)\n",
    "print(df['marital_status'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54efba3",
   "metadata": {},
   "source": [
    "#### 1.2.3: ✔Procedure type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60293cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in proceduretype:\n",
    "    print(x,': ',df[x].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b46f11",
   "metadata": {},
   "source": [
    "#### 1.2.4: **Vitals / Blood Gases / Products + infection / Ventilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for Jahan/others\n",
    "# ventrate seems to be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833632bb",
   "metadata": {},
   "source": [
    "#### 1.2.5: ✔Comorbidities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ea6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in comorbidities:\n",
    "    print(x,': ',df[x].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6159531",
   "metadata": {},
   "source": [
    "#### 1.2.6: Admissions (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d358bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in adm_cat:\n",
    "    print(x,': ',df[x].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_careunit\n",
    "df.replace({'first_careunit':\n",
    "                {'Cardiac Vascular Intensive Care Unit (CVICU)':'CVICU',\n",
    "                'Coronary Care Unit (CCU)':'CCU',\n",
    "                'Medical Intensive Care Unit (MICU)':'MICU',\n",
    "                'Surgical Intensive Care Unit (SICU)':'SICU',\n",
    "                'Neuro Intermediate':'Neuro Inter',\n",
    "                'Medical/Surgical Intensive Care Unit (MICU/SICU)':'MICU/SICU',\n",
    "                'Trauma SICU (TSICU)':'TSICU',\n",
    "                'Neuro Surgical Intensive Care Unit (Neuro SICU)':'Neuro SICU'\n",
    "                }\n",
    "            }, \n",
    "            inplace=True)\n",
    "print(df['first_careunit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_careunit\n",
    "df.replace({'last_careunit':\n",
    "                {'Cardiac Vascular Intensive Care Unit (CVICU)':'CVICU',\n",
    "                'Coronary Care Unit (CCU)':'CCU',\n",
    "                'Medical Intensive Care Unit (MICU)':'MICU',\n",
    "                'Surgical Intensive Care Unit (SICU)':'SICU',\n",
    "                'Neuro Intermediate':'Neuro Inter',\n",
    "                'Medical/Surgical Intensive Care Unit (MICU/SICU)':'MICU/SICU',\n",
    "                'Trauma SICU (TSICU)':'TSICU',\n",
    "                'Neuro Surgical Intensive Care Unit (Neuro SICU)':'Neuro SICU'\n",
    "                }\n",
    "            }, \n",
    "            inplace=True)\n",
    "print(df['last_careunit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4578e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#admission_location\n",
    "df.replace({'admission_location':\n",
    "                {'TRANSFER FROM HOSP/EXTRAM':'TRANSFER FROM HOSPITAL',\n",
    "                'PHYS REFERRAL/NORMAL DELI':'PHYSICIAN REFERRAL',\n",
    "                'TRANSFER FROM SKILLED NUR':'TRANSFER FROM SKILLED NURSING FACILITY',\n",
    "                'INFORMATION NOT AVAILABLE':np.NaN,\n",
    "                'CLINIC REFERRAL':'CLINIC REFERRAL/PREMATURE',\n",
    "                'EMERGENCY ROOM ADMIT':'EMERGENCY ROOM',\n",
    "                }\n",
    "            }, \n",
    "            inplace=True)\n",
    "print(df['admission_location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a4471",
   "metadata": {},
   "source": [
    "#### 1.2.7: Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in others:\n",
    "#     print(x,': ',df[x].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe0ff5",
   "metadata": {},
   "source": [
    "### 1.3: Parsing time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22247390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vent_array'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def va_parser(row, output=6):\n",
    "    \"\"\"\n",
    "    Takes row from `df` returns a list of starttime, endtime, vent duration \n",
    "    for first and (if applicable) second intubations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : row in df\n",
    "    output_ : select which output you want (use list index below) - e.g. args=[6] for all output when using df.apply()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    single list variable containing  \n",
    "        [0] int_time1: first intubation starttime\n",
    "        [1] ext_time1: first intubation endtime\n",
    "        [2] duration1: first intubation duration\n",
    "        [3] int_time2: second intubation starttime\n",
    "        [4] ext_time2: second intubation endtime \n",
    "        [5] duration2: second intubation duration\n",
    "        [6] all\n",
    "\n",
    "    \"\"\"\n",
    "    int_time1=np.NaN\n",
    "    ext_time1=np.NaN\n",
    "    duration1=np.NaN\n",
    "    int_time2=np.NaN\n",
    "    ext_time2=np.NaN\n",
    "    duration2=np.NaN\n",
    "    value = row['vent_array']\n",
    "    list=[]\n",
    "    '''a = value\n",
    "    print(value)'''\n",
    "    if value == np.NaN or pd.isna(value):\n",
    "        return np.NaN\n",
    "    a = value.replace(\"'\",'\"')\n",
    "    a = a.replace('\\n ...\\n',',').replace('\\n', ',').replace('...', '')\n",
    "    a = a.replace('datetime.','\"dt.')\n",
    "    a = a.replace('),', ')\",')\n",
    "    a = json.loads(a)\n",
    "    b = [(i['starttime'], i['endtime'], i['duration_hours']) for i in a]\n",
    "    int_time1=dt.datetime.strptime(b[0][0],'dt.datetime(%Y, %m, %d, %H, %M)')\n",
    "    ext_time1=dt.datetime.strptime(b[0][1],'dt.datetime(%Y, %m, %d, %H, %M)')\n",
    "    duration1=b[0][2]\n",
    "    \n",
    "    if output==0:\n",
    "        return int_time1\n",
    "    if output==1:\n",
    "        return ext_time1\n",
    "    if output==2:\n",
    "        return duration1\n",
    "\n",
    "    if len(b)>=2:\n",
    "        int_time2=dt.datetime.strptime(b[1][0],'dt.datetime(%Y, %m, %d, %H, %M)')\n",
    "        ext_time2=dt.datetime.strptime(b[1][1],'dt.datetime(%Y, %m, %d, %H, %M)')\n",
    "        duration2=b[1][2]\n",
    "    if output==3:\n",
    "        return int_time2\n",
    "    if output==4:\n",
    "        return ext_time2\n",
    "    if output==5:\n",
    "        return duration2\n",
    "    if output==6:\n",
    "        return int_time1, ext_time1, duration1, int_time2, ext_time2, duration2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc71015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['int_time1']=df.apply(va_parser, args=[0], axis=1)\n",
    "df['ext_time1']=df.apply(va_parser, args=[1], axis=1)\n",
    "df['duration1']=df.apply(va_parser, args=[2], axis=1)\n",
    "df['int_time2']=df.apply(va_parser, args=[3], axis=1)\n",
    "df['ext_time2']=df.apply(va_parser, args=[4], axis=1)\n",
    "df['duration2']=df.apply(va_parser, args=[5], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f27ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_parser(value, timeLimits=None):\n",
    "    if value == np.NaN or pd.isna(value):\n",
    "        return 0\n",
    "    a = value.replace(\"'\", '\"')\n",
    "    a = a.replace('\\n ...\\n',',').replace('\\n', ',').replace('...', '')\n",
    "    a = a.replace('datetime.', '\"dt.')\n",
    "    a = a.replace('\": None', '\": \"None\"')\n",
    "    for valuename in ['antibiotic','antibiotic_time']:\n",
    "        a = a.replace(f'), \"{valuename}\"', f')\", \"{valuename}\"')\n",
    "    a = json.loads(a)\n",
    "    b = [(eval(i['suspected_infection_time']), eval(i['antibiotic_time']), i['antibiotic'], i['specimen'], \n",
    "               i['positiveculture']) for i in a]\n",
    "    sus = [i[0] for i in b]\n",
    "    abx = [i[1] for i in b]\n",
    "    pos = [i[4] for i in b]\n",
    "    inf_ = 0\n",
    "    for i in range(len(sus)):\n",
    "        if sus[i]==None:\n",
    "            sus[i]=dt.datetime(1000, 1, 1, 0, 0)\n",
    "        if abx[i]==None:\n",
    "            abx[i]=dt.datetime(1000, 1, 1, 0, 0)\n",
    "        if ((sus[i]>= timeLimits[0] and sus[i]<=timeLimits[1]) or (abx[i]>= timeLimits[0] and abx[i]<=timeLimits[1])) and pos[i] == 1.0:\n",
    "            temp = 1\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    return inf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_parser(value, timeDelta=None, timeLimits=None, valuename='value'):\n",
    "    # timeDelta is timedelta in hours from earliest entry\n",
    "    # timeLimits = (startTime, endTime)\n",
    "    # if both timeDelta and timeLimits are provided, timeDelta overrules.\n",
    "    # if both are None, then all timepoints are accepted\n",
    "    if value == np.NaN or pd.isna(value):\n",
    "        return np.NaN, np.NaN, np.NaN\n",
    "    a = value.replace(\"'\", '\"')\n",
    "    a = a.replace('\\n ...\\n',',').replace('\\n', ',').replace('...', '')\n",
    "    a = a.replace('datetime.', '\"dt.')\n",
    "    a = a.replace(f'), \"{valuename}\"', f')\", \"{valuename}\"')\n",
    "    a = a.replace('\"unit\": None', '\"unit\": \"None\"')\n",
    "    a = a.replace('starttime', 'charttime')\n",
    "    a = json.loads(a)\n",
    "    b = [(eval(i['charttime']), i[valuename]) for i in a]\n",
    "    \n",
    "    if timeDelta:\n",
    "        startTime = min(b, key=lambda x:x[0])[0]\n",
    "        inc_b = [i[1] for i in b if i[0] <= startTime + dt.timedelta(hours=timeDelta)]\n",
    "    else:\n",
    "        if timeLimits:\n",
    "            inc_b = [i[1] for i in b if i[0] >= timeLimits[0] and i[0] <= timeLimits[1]]\n",
    "        else:\n",
    "            inc_b = [i[1] for i in b]\n",
    "    if len(inc_b) == 0:\n",
    "        return np.NaN, np.NaN, np.NaN\n",
    "    \n",
    "    return sum(inc_b) / len(inc_b), max(inc_b), min(inc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all rows where int_time1 OR ext_time1 are missing\n",
    "df = df[~(pd.isnull(df['int_time1']) | pd.isnull(df['ext_time1']))]\n",
    "df = df.reset_index()\n",
    "df = df.drop(axis=1, columns=['index', 'Unnamed: 0'], inplace=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22bd3c",
   "metadata": {},
   "source": [
    "### 1.4: Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72921c64",
   "metadata": {},
   "source": [
    "#### 1.4.0 Assessing for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6522c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check % missing values\n",
    "def missing_values_table(df): \n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(columns = {0: 'Missing Values', 1: '% Missing Values'})\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "missing_data = missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32333f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set limit and get list of variables missing above limit in `missing_cols`\n",
    "# missing_limit = 50 #allen\n",
    "missing_limit = 80 #marcel\n",
    "missing_cols = missing_data.loc[missing_data['% Missing Values']>missing_limit].index.tolist()\n",
    "print(missing_cols)\n",
    "missing_data = missing_data.loc[missing_data['% Missing Values']>missing_limit]\n",
    "missing_data = missing_data.sort_values(by=['% Missing Values'])\n",
    "pd.set_option('display.max_rows', None)\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d70f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c21841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(axis=1, columns=list(missing_data.index), inplace=False) #allen\n",
    "df = df.drop(axis=1, columns=[i for i in list(missing_data.index) if i not in ['duration2','int_time2','ext_time2','aado2','fio2','deathtime']], inplace=False) #marcel\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f665d8",
   "metadata": {},
   "source": [
    "#### 1.4.1 Beginning imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfForImpute = pd.DataFrame([0 for i in range(df.shape[0])])\n",
    "\n",
    "# generating timeseries summary values\n",
    "for column in timeseries:\n",
    "    if column not in df.columns:\n",
    "        continue\n",
    "    x = timeseries_valuenames[column] if column in timeseries_valuenames else \"value\"\n",
    "    meanList = []\n",
    "    maxList = []\n",
    "    minList = []\n",
    "    for i in range(len(df[column])):\n",
    "        y = ts_parser(df[column][i], timeLimits=(df['int_time1'][i].to_pydatetime(), df['ext_time1'][i].to_pydatetime()), valuename=x)\n",
    "        meanList.append(y[0])\n",
    "        maxList.append(y[1])\n",
    "        minList.append(y[2])\n",
    "    dfForImpute[column+'_mean'] = meanList\n",
    "    dfForImpute[column+'_max'] = maxList\n",
    "    dfForImpute[column+'_min'] = minList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating infection during ventilation binary values\n",
    "\n",
    "x = timeseries_valuenames[column] if column in timeseries_valuenames else \"value\"\n",
    "infList = []\n",
    "column='infection'\n",
    "for i in range(len(df[column])):\n",
    "    y = inf_parser(df[column][i], timeLimits=(df['int_time1'][i].to_pydatetime(), df['ext_time1'][i].to_pydatetime()))\n",
    "    infList.append(y)\n",
    "dfForImpute['infection_vent'] = infList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10238841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add on non-time data for imputation\n",
    "\n",
    "#extraColumns = [i for i in df.columns if i not in list(dfForImpute.columns) + timeseries + ['infection', 'vent_array', 'int_time1', 'ext_time1'] + ptinfo + adm_num] #allen\n",
    "extraColumns = [i for i in df.columns if i not in list(dfForImpute.columns) + timeseries + ['vent_array','infection'] + ptinfo + adm_num] #marcel\n",
    "\n",
    "for i in extraColumns:\n",
    "    if i in ('weight', 'height', 'duration1','duration2'):\n",
    "        dfForImpute[i] = df[i]\n",
    "    else:\n",
    "        dfForImpute[i] = df[i].astype('category')\n",
    "dfForImpute.drop(axis=1, columns=[0], inplace=True)\n",
    "dfForImpute2 = dfForImpute.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before imputation again\n",
    "dfForImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfForImpute2 = dfForImpute.drop(axis=1, columns=['int_time1', 'ext_time1', 'duration1','int_time2', 'ext_time2','duration2'])\n",
    "\n",
    "kds = mf.ImputationKernel(\n",
    "  dfForImpute2,\n",
    "  datasets=1,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "\n",
    "# Run the MICE algorithm for 3 iterations\n",
    "kds.mice(3)\n",
    "\n",
    "print(kds)\n",
    "\n",
    "dfImputed = kds.complete_data(dataset=0, inplace=False)\n",
    "print(dfImputed.isnull().sum(0))\n",
    "\n",
    "# after imputation\n",
    "dfImputed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77704536",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray([i.to_pydatetime() for i in df[\"int_time1\"]])\n",
    "z = np.asarray([i.to_pydatetime() for i in df[\"outtime\"]])\n",
    "dfImputed['icu_stay_duration'] = [i.total_seconds() for i in z-y]\n",
    "dfImputed[[i for i in adm_num if i != 'reint_time']] = df[[i for i in adm_num if i != 'reint_time']] #marcel\n",
    "dfImputed[['hadm_id','subject_id']] = df[['hadm_id','subject_id']]\n",
    "dfImputed[['int_time1', 'ext_time1', 'duration1','int_time2', 'ext_time2','duration2']] = df[['int_time1', 'ext_time1', 'duration1','int_time2', 'ext_time2','duration2']] #marcel not #allen\n",
    "dfImputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b202c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfImputed.to_csv('imputed.csv') #allen\n",
    "dfImputed.to_csv('imputed_m.csv')  #marcel"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b1f2d4191a73b69d030a477f7f557c00ce0852f571519640dfb2ad4928c756a"
  },
  "kernelspec": {
   "display_name": "tridentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
